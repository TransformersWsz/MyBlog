---
title: 两种神经网络参数初始化方法
mathjax: true
toc: true
date: 2024-06-21 01:28:57
updated: 2024-06-21 01:28:57
categories:
- Machine Learning
tags:
- Algorithm
- Neural Networks
---

重点介绍一下Xavier和Kaiming初始化：

<!--more-->

## Xavier

> 为了使得网络中信息更好的流动，每一层输出的方差应该尽量相等。

#### 正态分布参数初始化
$$
\mathcal{N}\left(0, \frac{2}{n_{\text {in }}+n_{\text {out }}}\right)
$$

#### 均匀分布参数初始化
$$
\mathcal{U}\left(-\sqrt{\frac{6}{n_{\text {in }}+n_{\text {out }}}}, \sqrt{\frac{6}{n_{\text {in }}+n_{\text {out }}}}\right)
$$

## Kaiming

Xavier初始化的问题在于，它只适用于线性激活函数，但实际上，对于深层神经网络来说，线性激活函数是没有价值，神经网络需要非线性激活函数(例如ReLU)来构建复杂网络。

> 前向传播时每层的方差都是1

> 反向传播时梯度的方差都是1

#### 正态分布参数初始化
$$
\mathcal{N}\left(0, \frac{2}{n_{\text {in }}}\right)
$$

#### 均匀分布参数初始化
$$
\mathcal{U}\left(-\sqrt{\frac{6}{n_{\text {in }}}}, \sqrt{\frac{6}{n_{\text {in }}}}\right)
$$

$n_{in}$表示每层输入的神经元数量

___

## 参考
- [ChatGPT: 什么是xavier和kaiming初始化，给出公式和详细解释](https://chatgpt.com/share/6c5856fb-e3d3-4ae0-8d1a-21a2b562888d)
- [Xavier参数初始化方法和Kaiming参数初始化方法详细介绍及其原理详解](https://blog.csdn.net/IronmanJay/article/details/128888954)