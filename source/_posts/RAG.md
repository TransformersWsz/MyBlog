---
title: RAG
mathjax: true
toc: true
date: 2024-05-12 14:20:49
updated: 2024-05-12 14:20:49
categories:
- NLP
tags:
- LLM
- RAG
---
现有的LLM已经具备了理解、生成、逻辑和记忆能力，RAG(Retrieval Augmented Generation)则是为其套上外挂，使LLM能够访问训练数据来源之外的权威知识库，并生成领域特定的内容，而无须重新训练模型。

<!--more-->

## RAG的优势
- 经济高效：LLM无须重新训练，即可访问和生成领域内容。
- 减轻幻觉：LLM根据用户输入，并根据它的训练语料生成内容。RAG引入了信息检索组件，该组件利用用户输入首先从新数据源提取信息。用户查询和相关信息都提供给LLM。LLM使用新知识及其训练数据来创建更好的响应。

当前信息
即使 LLM 的原始训练数据来源适合您的需求，但保持相关性也具有挑战性。RAG 允许开发人员为生成模型提供最新的研究、统计数据或新闻。他们可以使用 RAG 将 LLM 直接连接到实时社交媒体提要、新闻网站或其他经常更新的信息来源。然后，LLM 可以向用户提供最新信息。

增强用户信任度
RAG 允许 LLM 通过来源归属来呈现准确的信息。输出可以包括对来源的引文或引用。如果需要进一步说明或更详细的信息，用户也可以自己查找源文档。这可以增加对您的生成式人工智能解决方案的信任和信心。

更多开发人员控制权
借助 RAG，开发人员可以更高效地测试和改进他们的聊天应用程序。他们可以控制和更改 LLM 的信息来源，以适应不断变化的需求或跨职能使用。开发人员还可以将敏感信息的检索限制在不同的授权级别内，并确保 LLM 生成适当的响应。此外，如果 LLM 针对特定问题引用了错误的信息来源，他们还可以进行故障排除并进行修复。组织可以更自信地为更广泛的应用程序实施生成式人工智能技术。