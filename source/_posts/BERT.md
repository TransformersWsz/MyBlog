---
title: BERT
mathjax: true
date: 2019-07-28 22:22:15
categories:
- NLP
tags:
- Attention
- 论文阅读
---
`BERT` 的两阶段如下所示：

<!--more-->

{% asset_img 1.png %}

## Comparision Of Models
{% asset_img 2.png %}
___
## 参考
- [A Neural Probabilistic Language Model](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)
